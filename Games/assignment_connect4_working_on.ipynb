{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Connect 4\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 10, graduate students 11\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [1 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Goal state"
   ]
  },
  {
   "source": [
    "### Your code/answer goes here.\n",
    "- Initial State: empty board\n",
    "- Actions: drop a piece on arbitrary vertical line\n",
    "- Transition model: the new state resulting from dropping a piece\n",
    "- Goal state: forming a sequence of 4 to win the game"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the search space?"
   ]
  },
  {
   "source": [
    "### Your code/ answer goes here.\n",
    "Each grid has three different state, empty(0),the player(1), the opponent(-1). Hence, in a ($m * n$) board, the search space is less than $3^{m * n}$ because several sequences of 4 does not exist."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the namespace by removing all names defined by the user, if called without arguments. It can reduce the frequency of restarting kernel to clean all variables.\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [2 point]\n",
    "\n",
    "Use a numpy character array as the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=0)\n",
    "\n",
    "board = empty_board()\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of colors for the players use 'x' and 'o' to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 'x')`, where board is the current board position and player is the player whose next move it is and who the agent should play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the board and helper functions for:\n",
    "\n",
    "* The transition model (result).\n",
    "* The utility function.\n",
    "* Check for terminal states.\n",
    "* A check for available actions.\n",
    "* A function to visualize the board.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes.\n",
    "\n",
    "Implement an agent that plays randomly and let two random agents play against each other 1000 times. How often does each player win? Is the result expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to visualize the board\n",
    "def show_board(board,raw_display=False):\n",
    "    tmp_board = board.copy()\n",
    "    if raw_display==False:\n",
    "        tmp_board = tmp_board.astype(str)\n",
    "        tmp_board[tmp_board=='0'] = ' '\n",
    "        tmp_board[tmp_board=='1'] = 'x'\n",
    "        tmp_board[tmp_board=='-1'] = 'o'\n",
    "    print(tmp_board)\n",
    "    print()"
   ]
  },
  {
   "source": [
    "### In my raw board, I would use 0, 1 and -1 respectively to represent empty grid, the piece of player 'x' and player 'o'. It may look like what I show below. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']]\n[[0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "show_board(board)\n",
    "show_board(board,raw_display=True)"
   ]
  },
  {
   "source": [
    "### I use convolution calculation in place of successive nested for loops for win detection in order to get better performance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<img src=\"https://i.stack.imgur.com/nfjuC.png\" width=\"800\"/>",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "execution_count": 326
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://i.stack.imgur.com/nfjuC.png', width=800)"
   ]
  },
  {
   "source": [
    "### The function \"check_win\" could determine if a player wins or draw by passing parameter player. Its return values 1, 0, -1, 2 respectively represent win,draw, loss and unknown. The \"unknown\" means it can't determine right now, maybe next move."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "# return 1 as win, 0 as draw, -1 as unknown(it means the player don't win)\n",
    "# we have two players, one is using 1 as his piece, the other is using -1 as his piece\n",
    "# we use sequence of 4 as winning condition.\n",
    "def check_win(board,number=4):\n",
    "    player = 1\n",
    "    opponent = -1 \n",
    "    horizontal_sequence = np.ones((1,number),dtype=int)\n",
    "    vertical_sequence = np.transpose(horizontal_sequence)\n",
    "    diag1_sequence = np.eye(4)\n",
    "    diag2_sequence = np.fliplr(diag1_sequence)\n",
    "    detection_sequences = [\n",
    "        horizontal_sequence,\n",
    "        vertical_sequence,\n",
    "        diag1_sequence,\n",
    "        diag2_sequence\n",
    "    ]\n",
    "    for sequence in detection_sequences:\n",
    "        if (convolve2d(board == player, sequence, mode=\"valid\") == number).any(): \n",
    "            return 1\n",
    "        elif (convolve2d(board == opponent, sequence, mode=\"valid\") == number).any():\n",
    "            return -1\n",
    "\n",
    "    if np.count_nonzero(board==0)<1: return 0\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for terminal states\n",
    "# return win as 1, draw as 0, loss as -1 and 2 as non-terminal state \n",
    "def is_terminal(state,player=1,number=4):\n",
    "    if player==1: opponent = -1\n",
    "    else : opponent = 1\n",
    "\n",
    "    goal = check_win(state,number)\n",
    "\n",
    "    if 0 == goal : return 0\n",
    "    elif goal==player : return 1\n",
    "    elif goal==-player : return -1\n",
    "    else : return goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "metadata": {},
     "execution_count": 329
    }
   ],
   "source": [
    "# A check for available actions.\n",
    "def actions(board):\n",
    "    \"\"\"return possible actions as a vector of indices\"\"\"\n",
    "    return np.where(board[0,:] == 0)[0].tolist()\n",
    "\n",
    "show_board(board)\n",
    "actions(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transition model (result)\n",
    "def result(state,player,action):\n",
    "    state = state.copy()\n",
    "    available_r = np.where(state[:,action] == 0)[0]\n",
    "    if len(available_r) > 0 :\n",
    "        r = available_r[-1]\n",
    "        state[r,action] = player\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']]\n\n[[' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' ' ' ' ' ' ' ' ']\n [' ' ' ' ' ' 'o' ' ' ' ' ' ']\n [' ' ' ' ' ' 'x' ' ' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "show_board(board)\n",
    "print()\n",
    "board = result(board,1,3)\n",
    "board = result(board,-1,3)\n",
    "show_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A completely randomized player agent\n",
    "def random_player(board, player = None):\n",
    "    \"\"\"Simple player that chooses a random empy square. player is unused\"\"\"\n",
    "    return np.random.choice(actions(board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_player(player, agent1_kernel, agent2_kernel):\n",
    "    if player == 1:\n",
    "        return -1, agent2_kernel\n",
    "    else:\n",
    "        return 1, agent1_kernel\n",
    "\n",
    "def play(empty_board_kernel, agent1_kernel, agent2_kernel, N = 100, debug=False, **kwargs):\n",
    "    \"\"\"Let two agents play each other N times. \"agent1\" starts first. \"agent1\" and \"agent2\" are agent functions that \n",
    "    get the board as the percept and return their next action.\"\"\"\n",
    "    results = {'agent1': 0, 'agent2': 0, 'draw': 0}\n",
    "    player_dict = {1:'agent1',-1:'agent2',0:'draw'}\n",
    "\n",
    "    for i in range(N):\n",
    "        # board = empty_board_kernel(shape=empty_board_shape)\n",
    "        board = empty_board_kernel()\n",
    "        # print(board.shape)\n",
    "        player, kernel = 1, agent1_kernel\n",
    "        \n",
    "        while True:\n",
    "            a = kernel(board, player)\n",
    "            board = result(board, player, a)\n",
    "            \n",
    "            goal = check_win(board,**kwargs)\n",
    "            if goal != 2:\n",
    "                results[player_dict[goal]] += 1\n",
    "                break\n",
    "            \n",
    "            player, kernel = switch_player(player, agent1_kernel, agent2_kernel)\n",
    "\n",
    "        if debug: show_board(board)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "source": [
    "Implement an agent that plays randomly and let two random agents play against each other 1000 times. How often does each player win? Is the result expected? \n",
    "\n",
    "### Based on the result of two random agents playing 1000 times in 10 big rounds, the random agent moved first looks like having an advantage over the other. I thought they may have equal probability to win but the results were beyond my expectation.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 569, 'agent2': 426, 'draw': 5}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 551, 'agent2': 446, 'draw': 3}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 565, 'agent2': 432, 'draw': 3}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 564, 'agent2': 433, 'draw': 3}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 558, 'agent2': 441, 'draw': 1}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 590, 'agent2': 406, 'draw': 4}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 564, 'agent2': 433, 'draw': 3}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 571, 'agent2': 426, 'draw': 3}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 572, 'agent2': 426, 'draw': 2}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'agent1': 561, 'agent2': 436, 'draw': 3}"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "913 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 -r 1 display(play(lambda: empty_board(shape=(6,7)), random_player, random_player, N = 1000, number=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [4 points]\n",
    "\n",
    "### Implement the search starting from a given board and specifying the player.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 \\times 4$) and/or changing the winning rule to connect 3 instead of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Describe and implement a simple move ordering strategy. How does this strategy influence the time it takes to \n",
    "make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [3 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge task [+ 1 bonus point]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [1 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+1 Bonus point].\n",
    "\n",
    "### Pure Monte Carlos Search\n",
    "\n",
    "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move is? You can use Pure Monte Carlo Search or any algorithms \n",
    "that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}